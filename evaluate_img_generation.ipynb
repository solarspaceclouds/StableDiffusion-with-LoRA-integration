{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation via Inception Score\n",
    "\n",
    "\n",
    "The Inception Score (IS) is a popular metric used to evaluate the quality of images generated by models such as Generative Adversarial Networks (GANs). \n",
    "It measures two key aspects of the generated images: \n",
    "1. Quality and \n",
    "2. Diversity. \n",
    "\n",
    "The score is derived from the Inception model, which is a deep convolutional neural network pre-trained on ImageNet for image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models.inception import inception_v3\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder of generated images\n",
    "image_folder_path = 'generated_images/'\n",
    "\n",
    "# Define the transform to resize and normalize images\n",
    "# Note: Normalization uses the InceptionV3's expected mean and std\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = ImageFolder(root=image_folder_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inception_score(imgs, cuda=True, batch_size=32, resize=True, splits=1):\n",
    "    \"\"\"Computes the inception score of the generated images.\n",
    "    imgs -- A list or iterator of PIL Image objects or a PyTorch DataLoader returning PIL images\n",
    "    cuda -- If True, use GPU for computation\n",
    "    batch_size -- Batch size for feeding into Inception v3\n",
    "    resize -- Resize input images to 299x299 if not already done\n",
    "    splits -- Number of splits for calculating the score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if imgs is a DataLoader\n",
    "    if not isinstance(imgs, DataLoader):\n",
    "        imgs = DataLoader(imgs, batch_size=batch_size)\n",
    "\n",
    "    # Set up dtype\n",
    "    dtype = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "    # Set up inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
    "    inception_model.eval()\n",
    "    up = torch.nn.Upsample(size=(299, 299), mode='bilinear').type(dtype) if resize else None\n",
    "\n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return torch.nn.functional.softmax(x, dim=1).data.cpu().numpy()\n",
    "\n",
    "    # Transform for input images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)) if resize else transforms.Lambda(lambda x: x),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((len(imgs.dataset), 1000))\n",
    "\n",
    "    \n",
    "    for i, (batch, _) in enumerate(imgs, 0):  # Assuming imgs is a DataLoader\n",
    "        # Check if the batch needs conversion\n",
    "        if not torch.is_tensor(batch[0]):\n",
    "            batch = torch.stack([transform(img).type(dtype) for img in batch])\n",
    "        else:\n",
    "            batch = batch.type(dtype)\n",
    "        \n",
    "        batch_size_i = batch.size(0)\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batch)\n",
    "\n",
    "\n",
    "    # Calculate scores\n",
    "    split_scores = []\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (len(preds) // splits): (k+1) * (len(preds) // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = [entropy(pyx, py) for pyx in part]\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solarspaceclouds/Desktop/lora/lora_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/solarspaceclouds/Desktop/lora/lora_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: Mean = 2.1783351147759924, Std = 0.3104690459466458\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Compute the Inception Score\n",
    "    mean_score, std_score = inception_score(dataloader, cuda=True, resize=False, splits=10)\n",
    "\n",
    "    print(f\"Inception Score: Mean = {mean_score}, Std = {std_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLDR Explanation of the Inception Score results\n",
    "Interpretation\n",
    "- A mean Inception Score of around 2.18 with a standard deviation of 0.31 suggests that the model produces images of:\n",
    "    - moderate quality and \n",
    "    - moderate diversity. \n",
    "- The images are likely recognizable and varied to some extent, but there may be room for improvement in both the realism and diversity of the images to achieve higher scores. \n",
    "\n",
    "- The standard deviation indicates that the model's performance is somewhat consistent, but there could be noticeable differences in the quality or diversity of images in different batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Explanation of the Inception Score results of Mean and Standard Deviation\n",
    "\n",
    "## Mean of the Inception Score (2.1783351147759924)\n",
    "### Quality: \n",
    "The mean value of the Inception Score reflects the average quality of the generated images. A higher mean score suggests that, on average, the images are more realistic and contain recognizable objects according to the Inception model. \n",
    "\n",
    "### Interpretation of Quality of generated images based on Mean: \n",
    "Mean score of 2.18 indicates that the generated images have a moderate level of quality. In the context of Inception Scores, higher values (e.g., scores closer to or above 10) are typically seen in very high-quality models. However, the interpretation of \"high quality\" is relative and depends on the specific dataset and task.\n",
    "\n",
    "### Diversity: \n",
    "The score also captures the diversity of the generated images. A higher score implies that the model can generate a variety of images across different classes. The diversity aspect is evaluated by measuring how confidently the Inception model predicts different classes for different generated images. \n",
    "\n",
    "### Interpretation of Diversity of generated images based on Mean: \n",
    "Mean score of 2.18 indicates that the generated images have a moderate level of diversity among the generated images.\n",
    "\n",
    "\n",
    "## Standard Deviation of the Inception Score (0.3104690459466458)\n",
    "\n",
    "### Consistency: \n",
    "The standard deviation provides insight into the consistency of the Inception Score across different sets of generated images. A lower standard deviation indicates that the Inception Scores are more consistent across different batches of generated images, while a higher standard deviation suggests variability in the quality and diversity of images across batches.\n",
    "\n",
    " \n",
    "### Intepretation of Consistency of generated images based on Standard Deviation:\n",
    " standard deviation of 0.31 indicates that there is some variability in the quality and diversity of the generated images, but it's not excessively high. This suggests that while there is some inconsistency in how the model performs across different sets of generated images, the level of variation is relatively moderate.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Notes: \n",
    "It's important to note that while the Inception Score can provide useful insights into the performance of a generative model, it is not without limitations. \n",
    "\n",
    "It depends on the Inception model, which is trained on ImageNet and may not fully capture quality or diversity aspects specific to different datasets or domains. \n",
    "\n",
    "Additionally, it does not measure how well the generated images match the target distribution (i.e., the real images). Therefore it is beneficial to use the Inception Score in conjunction with other evaluation metrics and qualitative assessments to get a comprehensive understanding of a model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
